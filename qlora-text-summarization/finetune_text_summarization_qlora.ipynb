{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:12.366708Z",
     "iopub.status.busy": "2024-03-15T13:26:12.366401Z",
     "iopub.status.idle": "2024-03-15T13:26:12.371104Z",
     "shell.execute_reply": "2024-03-15T13:26:12.370111Z",
     "shell.execute_reply.started": "2024-03-15T13:26:12.366678Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install peft trl bitsandbytes accelerate evaluate rouge_score bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:25:59.907474Z",
     "iopub.status.busy": "2024-03-15T13:25:59.906608Z",
     "iopub.status.idle": "2024-03-15T13:26:12.364462Z",
     "shell.execute_reply": "2024-03-15T13:26:12.363461Z",
     "shell.execute_reply.started": "2024-03-15T13:25:59.907436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:12.372394Z",
     "iopub.status.busy": "2024-03-15T13:26:12.372104Z",
     "iopub.status.idle": "2024-03-15T13:26:20.455214Z",
     "shell.execute_reply": "2024-03-15T13:26:20.454228Z",
     "shell.execute_reply.started": "2024-03-15T13:26:12.372370Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-15 13:26:18.486509: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-15 13:26:18.486561: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-15 13:26:18.488039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import wandb\n",
    "import os\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "from datasets import Dataset, load_dataset\n",
    "from huggingface_hub import notebook_login, login\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings('ignore')\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "bert_score = evaluate.load('bertscore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:20.457931Z",
     "iopub.status.busy": "2024-03-15T13:26:20.456742Z",
     "iopub.status.idle": "2024-03-15T13:26:53.721199Z",
     "shell.execute_reply": "2024-03-15T13:26:53.720212Z",
     "shell.execute_reply.started": "2024-03-15T13:26:20.457901Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlinusx\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240315_132622-eoon3d8c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/linusx/dialog-summarization/runs/eoon3d8c' target=\"_blank\">valiant-lake-11</a></strong> to <a href='https://wandb.ai/linusx/dialog-summarization' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/linusx/dialog-summarization' target=\"_blank\">https://wandb.ai/linusx/dialog-summarization</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/linusx/dialog-summarization/runs/eoon3d8c' target=\"_blank\">https://wandb.ai/linusx/dialog-summarization/runs/eoon3d8c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/linusx/dialog-summarization/runs/eoon3d8c?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7eed37e6b1c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "# Start a W&B run\n",
    "wandb.login()\n",
    "wandb.init(project=\"dialog-summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.724699Z",
     "iopub.status.busy": "2024-03-15T13:26:53.724422Z",
     "iopub.status.idle": "2024-03-15T13:26:53.760193Z",
     "shell.execute_reply": "2024-03-15T13:26:53.759244Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.724673Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/dialogsum/CSV/train.csv\", nrows=2000)\n",
    "df.columns = [str(q).strip() for q in df.columns]\n",
    "\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.761857Z",
     "iopub.status.busy": "2024-03-15T13:26:53.761582Z",
     "iopub.status.idle": "2024-03-15T13:26:53.767918Z",
     "shell.execute_reply": "2024-03-15T13:26:53.766934Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.761832Z"
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = \"\"\"\n",
    "Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
    "\"\"\".strip()\n",
    "\n",
    "def generate_training_prompt(\n",
    "    conversation: str, summary: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"    \n",
    "### Instruction: {system_prompt}\n",
    "        \n",
    "### Input: {conversation.strip()}\n",
    "               \n",
    "### Response: {summary}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.769468Z",
     "iopub.status.busy": "2024-03-15T13:26:53.769208Z",
     "iopub.status.idle": "2024-03-15T13:26:53.780449Z",
     "shell.execute_reply": "2024-03-15T13:26:53.779513Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.769445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Instruction: Below is a conversation between a human and an AI agent. Write a summary of the conversation.\n",
      "        \n",
      "### Input: #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today? #Person2#: I found it would...\n",
      "               \n",
      "### Response: Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll gi...\n"
     ]
    }
   ],
   "source": [
    "def create_conversation_text(data_point):\n",
    "    return data_point[\"dialogue\"]\n",
    "\n",
    "\n",
    "def generate_text(data_point):\n",
    "    summary = data_point[\"summary\"]\n",
    "    conversation_text = create_conversation_text(data_point)\n",
    "    return {\n",
    "        \"conversation\": conversation_text,\n",
    "        \"summary\": summary,\n",
    "        \"text\": generate_training_prompt(conversation_text, summary),\n",
    "    }\n",
    "\n",
    "# Example usage with a new dataset format\n",
    "example_data_point = {\n",
    "    \"id\": \"train_0\",\n",
    "    \"dialogue\": \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today? #Person2#: I found it would...\",\n",
    "    \"summary\": \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll gi...\",\n",
    "    \"topic\": \"get a check-up\"\n",
    "}\n",
    "\n",
    "\n",
    "example = generate_text(example_data_point)\n",
    "print(example[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.781824Z",
     "iopub.status.busy": "2024-03-15T13:26:53.781558Z",
     "iopub.status.idle": "2024-03-15T13:26:53.794366Z",
     "shell.execute_reply": "2024-03-15T13:26:53.793474Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.781796Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def process_dataset(data: Dataset) -> Dataset:\n",
    "    \"\"\"\n",
    "    This function processes the dataset to include only the necessary columns.\n",
    "    \"\"\"\n",
    "    # First, apply generate_text to each record in the dataset\n",
    "    processed_data = data.map(generate_text)\n",
    "\n",
    "\n",
    "    # Then, remove unnecessary columns\n",
    "    columns_to_remove = [col for col in processed_data.column_names if col not in [\"conversation\", \"summary\", \"text\"]]\n",
    "    return processed_data.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.798712Z",
     "iopub.status.busy": "2024-03-15T13:26:53.798049Z",
     "iopub.status.idle": "2024-03-15T13:26:53.895931Z",
     "shell.execute_reply": "2024-03-15T13:26:53.895103Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.798679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87315afce14d4855b705a0bdfc834e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process the entire dataset\n",
    "processed_dataset = process_dataset(dataset)\n",
    "\n",
    "\n",
    "# Split the processed dataset into train, validation, and test sets\n",
    "train_dataset = processed_dataset.shuffle(seed=42).select(range(0, int(0.8 * len(processed_dataset))))\n",
    "validation_dataset = processed_dataset.shuffle(seed=42).select(range(int(0.8 * len(processed_dataset)), int(0.9 * len(processed_dataset))))\n",
    "test_dataset = processed_dataset.shuffle(seed=42).select(range(int(0.9 * len(processed_dataset)), len(processed_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.897272Z",
     "iopub.status.busy": "2024-03-15T13:26:53.896941Z",
     "iopub.status.idle": "2024-03-15T13:26:53.905353Z",
     "shell.execute_reply": "2024-03-15T13:26:53.904383Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.897242Z"
    }
   },
   "outputs": [],
   "source": [
    "CUSTOM_DEVICE_MAP =  {\n",
    " 'model.embed_tokens': 0,\n",
    " 'model.layers.0': 0,\n",
    " 'model.layers.1': 0,\n",
    " 'model.layers.2': 0,\n",
    " 'model.layers.3': 0,\n",
    " 'model.layers.4': 0,\n",
    " 'model.layers.5': 0,\n",
    " 'model.layers.6': 0,\n",
    " 'model.layers.7': 0,\n",
    " 'model.layers.8': 0,\n",
    " 'model.layers.9': 0,\n",
    " 'model.layers.10': 0,\n",
    " 'model.layers.11': 0,\n",
    " 'model.layers.12': 0,\n",
    " 'model.layers.13': 0,\n",
    " 'model.layers.14': 1,\n",
    " 'model.layers.15': 1,\n",
    " 'model.layers.16': 1,\n",
    " 'model.layers.17': 1,\n",
    " 'model.layers.18': 1,\n",
    " 'model.layers.19': 1,\n",
    " 'model.layers.20': 1,\n",
    " 'model.layers.21': 1,\n",
    " 'model.layers.22': 1,\n",
    " 'model.layers.23': 1,\n",
    " 'model.layers.24': 1,\n",
    " 'model.layers.25': 1,\n",
    " 'model.layers.26': 1,\n",
    " 'model.layers.27': 1,\n",
    " 'model.layers.28': 1,\n",
    " 'model.layers.29': 1,\n",
    " 'model.layers.30': 1,\n",
    " 'model.layers.31': 1,\n",
    " 'model.norm': 1,\n",
    " 'lm_head': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:26:53.906953Z",
     "iopub.status.busy": "2024-03-15T13:26:53.906419Z",
     "iopub.status.idle": "2024-03-15T13:27:00.721770Z",
     "shell.execute_reply": "2024-03-15T13:27:00.720646Z",
     "shell.execute_reply.started": "2024-03-15T13:26:53.906920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ce3df750904e548861886147159e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = 'NousResearch/Llama-2-7b-chat-hf'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    use_safetensors=True,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=CUSTOM_DEVICE_MAP,\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:27:01.812689Z",
     "iopub.status.busy": "2024-03-15T13:27:01.812263Z",
     "iopub.status.idle": "2024-03-15T13:27:01.822605Z",
     "shell.execute_reply": "2024-03-15T13:27:01.821703Z",
     "shell.execute_reply.started": "2024-03-15T13:27:01.812662Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quant_method': <QuantizationMethod.BITS_AND_BYTES: 'bitsandbytes'>,\n",
       " '_load_in_8bit': False,\n",
       " '_load_in_4bit': True,\n",
       " 'llm_int8_threshold': 6.0,\n",
       " 'llm_int8_skip_modules': None,\n",
       " 'llm_int8_enable_fp32_cpu_offload': False,\n",
       " 'llm_int8_has_fp16_weight': False,\n",
       " 'bnb_4bit_quant_type': 'nf4',\n",
       " 'bnb_4bit_use_double_quant': False,\n",
       " 'bnb_4bit_compute_dtype': 'float16',\n",
       " 'load_in_4bit': True,\n",
       " 'load_in_8bit': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False\n",
    "model.config.quantization_config.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:27:01.824367Z",
     "iopub.status.busy": "2024-03-15T13:27:01.824022Z",
     "iopub.status.idle": "2024-03-15T13:27:01.832600Z",
     "shell.execute_reply": "2024-03-15T13:27:01.831778Z",
     "shell.execute_reply.started": "2024-03-15T13:27:01.824336Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_alpha = 32\n",
    "lora_dropout = 0.05\n",
    "lora_r = 16\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:27:01.847692Z",
     "iopub.status.busy": "2024-03-15T13:27:01.847376Z",
     "iopub.status.idle": "2024-03-15T13:27:01.859063Z",
     "shell.execute_reply": "2024-03-15T13:27:01.858229Z",
     "shell.execute_reply.started": "2024-03-15T13:27:01.847663Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_prompt(\n",
    "    conversation: str, system_prompt: str = DEFAULT_SYSTEM_PROMPT\n",
    ") -> str:\n",
    "    return f\"\"\"### Instruction: {system_prompt}\n",
    "\n",
    "### Input:\n",
    "{conversation.strip()}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "def summarize(model, text: str):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to('cuda:0')\n",
    "    inputs_length = len(inputs[\"input_ids\"][0])\n",
    "    with torch.inference_mode():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.0001)\n",
    "    return tokenizer.decode(outputs[0][inputs_length:], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def generate_summaries(model, dataset, tokenizer, num_samples=5):\n",
    "    summaries = []\n",
    "    for i, example in enumerate(dataset):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        print(i)\n",
    "        prompt = generate_prompt(example['conversation'])\n",
    "        summary = summarize(model, prompt)\n",
    "        summaries.append({'conversation': example['conversation'], 'generated_summary': summary})\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summaries before fine-tuning\n",
    "original_summaries = generate_summaries(model, test_dataset, tokenizer, num_samples=50)\n",
    "\n",
    "# Convert to DataFrame and log to W&B\n",
    "df_original = pd.DataFrame(original_summaries)\n",
    "actual_summaries = pd.DataFrame(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute scores before finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = rouge.compute(predictions=df_original.generated_summary, references=actual_summaries.summary.iloc[:50])\n",
    "bert_scores = bert_score.compute(predictions=df_original.generated_summary, references=actual_summaries.summary.iloc[:50], lang=\"en\")\n",
    "\n",
    "print('Rouge: ', rouge_scores)\n",
    "print('BERTScore Precision: ', np.mean(bert_scores['precision']))\n",
    "print('BERTScore Recall: ', np.mean(bert_scores['recall']))\n",
    "print('BERTScore F1: ', np.mean(bert_scores['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:29:38.682270Z",
     "iopub.status.busy": "2024-03-15T13:29:38.681875Z",
     "iopub.status.idle": "2024-03-15T13:29:38.692935Z",
     "shell.execute_reply": "2024-03-15T13:29:38.691892Z",
     "shell.execute_reply.started": "2024-03-15T13:29:38.682227Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"dialog-summarization-llama-2-finetuned\"\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-4,\n",
    "    fp16=True,\n",
    "    max_grad_norm=0.3,\n",
    "    num_train_epochs=20,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_steps=0.2,\n",
    "    warmup_ratio=0.05,\n",
    "    save_strategy=\"epoch\",\n",
    "    group_by_length=True,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    report_to=\"wandb\",  # Set report_to here\n",
    "    save_safetensors=True,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    seed=42,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:29:38.694727Z",
     "iopub.status.busy": "2024-03-15T13:29:38.694338Z",
     "iopub.status.idle": "2024-03-15T13:29:39.212417Z",
     "shell.execute_reply": "2024-03-15T13:29:39.211449Z",
     "shell.execute_reply.started": "2024-03-15T13:29:38.694687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a684dbee14fc454eb30f0bc8f1daa51b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/400 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b47095ce244c7d93e0869e480df637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=4096,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T13:29:39.214350Z",
     "iopub.status.busy": "2024-03-15T13:29:39.213930Z",
     "iopub.status.idle": "2024-03-15T15:48:32.567873Z",
     "shell.execute_reply": "2024-03-15T15:48:32.566627Z",
     "shell.execute_reply.started": "2024-03-15T13:29:39.214300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 2:11:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.745500</td>\n",
       "      <td>1.654858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.326700</td>\n",
       "      <td>1.320741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.155600</td>\n",
       "      <td>1.229804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.090800</td>\n",
       "      <td>1.223995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.121900</td>\n",
       "      <td>1.221663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.094100</td>\n",
       "      <td>1.226037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.159700</td>\n",
       "      <td>1.235341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.073700</td>\n",
       "      <td>1.244705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.022800</td>\n",
       "      <td>1.252475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.040100</td>\n",
       "      <td>1.271391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.006400</td>\n",
       "      <td>1.290393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.900600</td>\n",
       "      <td>1.300022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.034400</td>\n",
       "      <td>1.314983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>1.332614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.991700</td>\n",
       "      <td>1.354274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.967100</td>\n",
       "      <td>1.356476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.713900</td>\n",
       "      <td>1.370197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.840400</td>\n",
       "      <td>1.374456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.899100</td>\n",
       "      <td>1.375085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.829200</td>\n",
       "      <td>1.375416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune your model\n",
    "trainer.train()\n",
    "\n",
    "# Generate summaries after fine-tuning\n",
    "fine_tuned_summaries = generate_summaries(trainer.model, test_dataset, tokenizer, num_samples=5)\n",
    "\n",
    "# Convert to DataFrame and log to W&B\n",
    "df_fine_tuned = pd.DataFrame(fine_tuned_summaries)\n",
    "wandb.log({\"fine_tuned_summaries\": wandb.Table(dataframe=df_fine_tuned)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-15T16:08:20.301133Z",
     "iopub.status.busy": "2024-03-15T16:08:20.300770Z",
     "iopub.status.idle": "2024-03-15T16:08:20.626968Z",
     "shell.execute_reply": "2024-03-15T16:08:20.625815Z",
     "shell.execute_reply.started": "2024-03-15T16:08:20.301104Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model('/kaggle/working/best_ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.make_archive('llama2_dialog_sum_2', 'zip', '/kaggle/working/best_ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model and score it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = '/kaggle/working/best_ckpt'\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    use_safetensors=True,\n",
    "    quantization_config=bnb_config,\n",
    "    trust_remote_code=True,\n",
    "    device_map=CUSTOM_DEVICE_MAP,\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_summaries_df = pd.DataFrame(generate_summaries(model, test_dataset, tokenizer, num_samples=50))\n",
    "\n",
    "rouge_scores = rouge.compute(predictions=finetuned_summaries_df.generated_summary, references=actual_summaries.summary.iloc[:50])\n",
    "bert_scores = bert_score.compute(predictions=finetuned_summaries_df.generated_summary, references=actual_summaries.summary.iloc[:50], lang=\"en\")\n",
    "\n",
    "print('Rouge: ', rouge_scores)\n",
    "print('BERTScore Precision: ', np.mean(bert_scores['precision']))\n",
    "print('BERTScore Recall: ', np.mean(bert_scores['recall']))\n",
    "print('BERTScore F1: ', np.mean(bert_scores['f1']))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3659633,
     "sourceId": 6354265,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
